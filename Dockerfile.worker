FROM nvidia/cuda:12.1.1-devel-ubuntu22.04 AS builder

RUN apt-get update && apt-get upgrade -y \
    && apt-get install -y git build-essential \
    python3 \
    python3-pip \
    gcc \
    wget \
    cmake \
    ocl-icd-opencl-dev \
    opencl-headers \
    clinfo \
    ninja-build \
    libclblast-dev \
    libopenblas-dev \
    libgomp1 \
    && mkdir -p /etc/OpenCL/vendors \
    && echo "libnvidia-opencl.so.1" > /etc/OpenCL/vendors/nvidia.icd

ENV LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/compat:$LD_LIBRARY_PATH
ENV LLAMA_CUBLAS=1
ENV CMAKE_CUDA_ARCHITECTURES="86" 

COPY llama.cpp /home/appuser/app/llama.cpp
# RUN git clone --depth 1 https://github.com/ggml-org/llama.cpp.git  
WORKDIR /home/appuser/app/llama.cpp

RUN cmake -B build -G Ninja \
    -DCMAKE_BUILD_TYPE=Release \
    -DGGML_CUDA=ON \
    -DCMAKE_CUDA_ARCHITECTURES="86" \
    -DLLAMA_CURL=OFF \
    -DLLAMA_BUILD_TESTS=OFF

RUN cmake --build build --config Release --target llama-server

# --- Runtime Stage ---
FROM nvidia/cuda:12.1.1-runtime-ubuntu22.04

RUN apt-get update && apt-get install -y --no-install-recommends \
    libopenblas0 \
    libgomp1 \
    libnuma1 \
    python3 \
    python3-pip \
    libffi-dev \
    libssl-dev \
    poppler-utils \
    libreoffice \
    libgomp1 \
    ca-certificates \
    && apt-get clean && rm -rf /var/lib/apt/lists/*

RUN ldconfig
ENV LD_LIBRARY_PATH=/app/llama.cpp/build/bin:$LD_LIBRARY_PATH

RUN useradd -ms /bin/bash appuser
WORKDIR /home/appuser/app
RUN mkdir -p /home/appuser/app/models
RUN pip3 install --no-cache-dir redis fastapi uvicorn

COPY --from=builder /home/appuser/app/llama.cpp /app/llama.cpp
COPY --from=builder /home/appuser/app/llama.cpp/build/bin/* /usr/local/bin/
COPY --from=builder /home/appuser/app/llama.cpp/build/bin/llama-server /usr/local/bin/
COPY --from=builder /home/appuser/app/llama.cpp/build/bin/libllama.so /usr/local/lib/
COPY --from=builder /home/appuser/app/llama.cpp/build/bin/libggml.so /usr/local/lib/
COPY --from=builder /home/appuser/app/llama.cpp/build/bin/libggml-base.so /usr/local/lib/
COPY --from=builder /home/appuser/app/llama.cpp/build/bin/libggml-cpu.so /usr/local/lib/
COPY --from=builder /home/appuser/app/llama.cpp/build/bin/libggml-cuda.so /usr/local/lib/

COPY workers/worker.py .

USER appuser
ENTRYPOINT ["python3", "worker.py"]
